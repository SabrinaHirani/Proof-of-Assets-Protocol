{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "d0a82619",
            "metadata": {},
            "source": [
                "Credits to [geohot](https://github.com/geohot/ai-notebooks/blob/master/mnist_gan.ipynb) for most of this code\n",
                "\n",
                "## Model Architecture and training"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "c22afe46",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Collecting pytorch_lightning\n",
                        "  Downloading pytorch_lightning-2.1.0-py3-none-any.whl.metadata (23 kB)\n",
                        "Requirement already satisfied: numpy>=1.17.2 in c:\\users\\sabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pytorch_lightning) (1.25.1)\n",
                        "Requirement already satisfied: torch>=1.12.0 in c:\\users\\sabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pytorch_lightning) (2.1.0)\n",
                        "Requirement already satisfied: tqdm>=4.57.0 in c:\\users\\sabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pytorch_lightning) (4.65.0)\n",
                        "Requirement already satisfied: PyYAML>=5.4 in c:\\users\\sabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pytorch_lightning) (6.0.1)\n",
                        "Requirement already satisfied: fsspec>2021.06.0 in c:\\users\\sabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (2023.6.0)\n",
                        "Collecting torchmetrics>=0.7.0 (from pytorch_lightning)\n",
                        "  Downloading torchmetrics-1.2.0-py3-none-any.whl.metadata (21 kB)\n",
                        "Requirement already satisfied: packaging>=20.0 in c:\\users\\sabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pytorch_lightning) (23.1)\n",
                        "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\sabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pytorch_lightning) (4.8.0)\n",
                        "Collecting lightning-utilities>=0.8.0 (from pytorch_lightning)\n",
                        "  Downloading lightning_utilities-0.9.0-py3-none-any.whl.metadata (4.6 kB)\n",
                        "Requirement already satisfied: requests in c:\\users\\sabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (2.31.0)\n",
                        "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\sabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (3.8.6)\n",
                        "Requirement already satisfied: filelock in c:\\users\\sabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.12.0->pytorch_lightning) (3.12.2)\n",
                        "Requirement already satisfied: sympy in c:\\users\\sabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.12.0->pytorch_lightning) (1.12)\n",
                        "Requirement already satisfied: networkx in c:\\users\\sabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.12.0->pytorch_lightning) (3.1)\n",
                        "Requirement already satisfied: jinja2 in c:\\users\\sabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=1.12.0->pytorch_lightning) (3.1.2)\n",
                        "Requirement already satisfied: colorama in c:\\users\\sabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.57.0->pytorch_lightning) (0.4.6)\n",
                        "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\sabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (23.1.0)\n",
                        "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in c:\\users\\sabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (3.2.0)\n",
                        "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\sabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (6.0.4)\n",
                        "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\sabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (4.0.3)\n",
                        "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\sabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.9.2)\n",
                        "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\sabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.4.0)\n",
                        "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\sabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.1)\n",
                        "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=1.12.0->pytorch_lightning) (2.1.3)\n",
                        "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (3.4)\n",
                        "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (1.26.16)\n",
                        "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (2023.5.7)\n",
                        "Requirement already satisfied: mpmath>=0.19 in c:\\users\\sabri\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch>=1.12.0->pytorch_lightning) (1.3.0)\n",
                        "Downloading pytorch_lightning-2.1.0-py3-none-any.whl (774 kB)\n",
                        "   ---------------------------------------- 0.0/774.6 kB ? eta -:--:--\n",
                        "    --------------------------------------- 10.2/774.6 kB ? eta -:--:--\n",
                        "    --------------------------------------- 10.2/774.6 kB ? eta -:--:--\n",
                        "   --- ----------------------------------- 61.4/774.6 kB 544.7 kB/s eta 0:00:02\n",
                        "   ---- ---------------------------------- 92.2/774.6 kB 655.4 kB/s eta 0:00:02\n",
                        "   ------ ------------------------------- 122.9/774.6 kB 654.9 kB/s eta 0:00:01\n",
                        "   ------- ------------------------------ 143.4/774.6 kB 655.8 kB/s eta 0:00:01\n",
                        "   -------- ----------------------------- 174.1/774.6 kB 655.4 kB/s eta 0:00:01\n",
                        "   -------- ----------------------------- 174.1/774.6 kB 655.4 kB/s eta 0:00:01\n",
                        "   ---------- --------------------------- 204.8/774.6 kB 623.6 kB/s eta 0:00:01\n",
                        "   ---------- --------------------------- 204.8/774.6 kB 623.6 kB/s eta 0:00:01\n",
                        "   ---------- --------------------------- 204.8/774.6 kB 623.6 kB/s eta 0:00:01\n",
                        "   ---------- --------------------------- 204.8/774.6 kB 623.6 kB/s eta 0:00:01\n",
                        "   ----------- -------------------------- 235.5/774.6 kB 465.5 kB/s eta 0:00:02\n",
                        "   ------------ ------------------------- 256.0/774.6 kB 462.8 kB/s eta 0:00:02\n",
                        "   ------------- ------------------------ 276.5/774.6 kB 460.6 kB/s eta 0:00:02\n",
                        "   ------------- ------------------------ 276.5/774.6 kB 460.6 kB/s eta 0:00:02\n",
                        "   -------------- ----------------------- 286.7/774.6 kB 411.4 kB/s eta 0:00:02\n",
                        "   --------------- ---------------------- 307.2/774.6 kB 422.4 kB/s eta 0:00:02\n",
                        "   --------------- ---------------------- 307.2/774.6 kB 422.4 kB/s eta 0:00:02\n",
                        "   --------------- ---------------------- 317.4/774.6 kB 393.3 kB/s eta 0:00:02\n",
                        "   ---------------- --------------------- 337.9/774.6 kB 388.2 kB/s eta 0:00:02\n",
                        "   ----------------- -------------------- 358.4/774.6 kB 390.8 kB/s eta 0:00:02\n",
                        "   ----------------- -------------------- 358.4/774.6 kB 390.8 kB/s eta 0:00:02\n",
                        "   ----------------- -------------------- 358.4/774.6 kB 390.8 kB/s eta 0:00:02\n",
                        "   ----------------- -------------------- 358.4/774.6 kB 390.8 kB/s eta 0:00:02\n",
                        "   ----------------- -------------------- 358.4/774.6 kB 390.8 kB/s eta 0:00:02\n",
                        "   ----------------- -------------------- 358.4/774.6 kB 390.8 kB/s eta 0:00:02\n",
                        "   ----------------- -------------------- 358.4/774.6 kB 390.8 kB/s eta 0:00:02\n",
                        "   ----------------- -------------------- 358.4/774.6 kB 390.8 kB/s eta 0:00:02\n",
                        "   ------------------ ------------------- 368.6/774.6 kB 290.4 kB/s eta 0:00:02\n",
                        "   ------------------- ------------------ 389.1/774.6 kB 295.8 kB/s eta 0:00:02\n",
                        "   ------------------- ------------------ 389.1/774.6 kB 295.8 kB/s eta 0:00:02\n",
                        "   ------------------- ------------------ 389.1/774.6 kB 295.8 kB/s eta 0:00:02\n",
                        "   ------------------- ------------------ 399.4/774.6 kB 273.6 kB/s eta 0:00:02\n",
                        "   ------------------- ------------------ 399.4/774.6 kB 273.6 kB/s eta 0:00:02\n",
                        "   ------------------- ------------------ 399.4/774.6 kB 273.6 kB/s eta 0:00:02\n",
                        "   -------------------- ----------------- 409.6/774.6 kB 253.1 kB/s eta 0:00:02\n",
                        "   -------------------- ----------------- 409.6/774.6 kB 253.1 kB/s eta 0:00:02\n",
                        "   --------------------- ---------------- 430.1/774.6 kB 251.1 kB/s eta 0:00:02\n",
                        "   --------------------- ---------------- 430.1/774.6 kB 251.1 kB/s eta 0:00:02\n",
                        "   ---------------------- --------------- 450.6/774.6 kB 256.1 kB/s eta 0:00:02\n",
                        "   ---------------------- --------------- 460.8/774.6 kB 250.7 kB/s eta 0:00:02\n",
                        "   ----------------------- -------------- 481.3/774.6 kB 257.7 kB/s eta 0:00:02\n",
                        "   ------------------------ ------------- 491.5/774.6 kB 258.9 kB/s eta 0:00:02\n",
                        "   ------------------------- ------------ 512.0/774.6 kB 265.3 kB/s eta 0:00:01\n",
                        "   -------------------------- ----------- 532.5/774.6 kB 269.6 kB/s eta 0:00:01\n",
                        "   -------------------------- ----------- 542.7/774.6 kB 270.4 kB/s eta 0:00:01\n",
                        "   --------------------------- ---------- 563.2/774.6 kB 272.3 kB/s eta 0:00:01\n",
                        "   ---------------------------- --------- 573.4/774.6 kB 273.1 kB/s eta 0:00:01\n",
                        "   ----------------------------- -------- 593.9/774.6 kB 274.7 kB/s eta 0:00:01\n",
                        "   ------------------------------ ------- 624.6/774.6 kB 280.9 kB/s eta 0:00:01\n",
                        "   ------------------------------ ------- 624.6/774.6 kB 280.9 kB/s eta 0:00:01\n",
                        "   ------------------------------ ------- 624.6/774.6 kB 280.9 kB/s eta 0:00:01\n",
                        "   -------------------------------- ----- 655.4/774.6 kB 280.9 kB/s eta 0:00:01\n",
                        "   --------------------------------- ---- 675.8/774.6 kB 284.0 kB/s eta 0:00:01\n",
                        "   ---------------------------------- --- 696.3/774.6 kB 288.9 kB/s eta 0:00:01\n",
                        "   ---------------------------------- --- 706.6/774.6 kB 285.7 kB/s eta 0:00:01\n",
                        "   ----------------------------------- -- 727.0/774.6 kB 290.3 kB/s eta 0:00:01\n",
                        "   ------------------------------------ - 737.3/774.6 kB 289.0 kB/s eta 0:00:01\n",
                        "   -------------------------------------  768.0/774.6 kB 297.5 kB/s eta 0:00:01\n",
                        "   -------------------------------------- 774.6/774.6 kB 296.5 kB/s eta 0:00:00\n",
                        "Downloading lightning_utilities-0.9.0-py3-none-any.whl (23 kB)\n",
                        "Downloading torchmetrics-1.2.0-py3-none-any.whl (805 kB)\n",
                        "   ---------------------------------------- 0.0/805.2 kB ? eta -:--:--\n",
                        "    --------------------------------------- 10.2/805.2 kB ? eta -:--:--\n",
                        "    --------------------------------------- 10.2/805.2 kB ? eta -:--:--\n",
                        "    --------------------------------------- 10.2/805.2 kB ? eta -:--:--\n",
                        "    --------------------------------------- 10.2/805.2 kB ? eta -:--:--\n",
                        "    --------------------------------------- 10.2/805.2 kB ? eta -:--:--\n",
                        "    --------------------------------------- 10.2/805.2 kB ? eta -:--:--\n",
                        "    --------------------------------------- 10.2/805.2 kB ? eta -:--:--\n",
                        "   - ------------------------------------- 41.0/805.2 kB 103.4 kB/s eta 0:00:08\n",
                        "   - ------------------------------------- 41.0/805.2 kB 103.4 kB/s eta 0:00:08\n",
                        "   -- ------------------------------------ 61.4/805.2 kB 130.9 kB/s eta 0:00:06\n",
                        "   -- ------------------------------------ 61.4/805.2 kB 130.9 kB/s eta 0:00:06\n",
                        "   -- ------------------------------------ 61.4/805.2 kB 130.9 kB/s eta 0:00:06\n",
                        "   ---- ---------------------------------- 92.2/805.2 kB 149.8 kB/s eta 0:00:05\n",
                        "   ---- ---------------------------------- 92.2/805.2 kB 149.8 kB/s eta 0:00:05\n",
                        "   ---- ---------------------------------- 92.2/805.2 kB 149.8 kB/s eta 0:00:05\n",
                        "   ----- -------------------------------- 112.6/805.2 kB 156.1 kB/s eta 0:00:05\n",
                        "   ----- -------------------------------- 112.6/805.2 kB 156.1 kB/s eta 0:00:05\n",
                        "   ----- -------------------------------- 122.9/805.2 kB 153.5 kB/s eta 0:00:05\n",
                        "   ----- -------------------------------- 122.9/805.2 kB 153.5 kB/s eta 0:00:05\n",
                        "   ------ ------------------------------- 143.4/805.2 kB 160.8 kB/s eta 0:00:05\n",
                        "   ------- ------------------------------ 163.8/805.2 kB 172.4 kB/s eta 0:00:04\n",
                        "   -------- ----------------------------- 174.1/805.2 kB 174.7 kB/s eta 0:00:04\n",
                        "   --------- ---------------------------- 194.6/805.2 kB 193.4 kB/s eta 0:00:04\n",
                        "   --------- ---------------------------- 194.6/805.2 kB 193.4 kB/s eta 0:00:04\n",
                        "   ---------- --------------------------- 225.3/805.2 kB 202.3 kB/s eta 0:00:03\n",
                        "   ----------- -------------------------- 245.8/805.2 kB 209.4 kB/s eta 0:00:03\n",
                        "   ------------ ------------------------- 256.0/805.2 kB 209.7 kB/s eta 0:00:03\n",
                        "   ------------- ------------------------ 276.5/805.2 kB 221.3 kB/s eta 0:00:03\n",
                        "   ------------- ------------------------ 276.5/805.2 kB 221.3 kB/s eta 0:00:03\n",
                        "   -------------- ----------------------- 307.2/805.2 kB 226.2 kB/s eta 0:00:03\n",
                        "   -------------- ----------------------- 307.2/805.2 kB 226.2 kB/s eta 0:00:03\n",
                        "   --------------- ---------------------- 327.7/805.2 kB 225.8 kB/s eta 0:00:03\n",
                        "   --------------- ---------------------- 327.7/805.2 kB 225.8 kB/s eta 0:00:03\n",
                        "   --------------- ---------------------- 337.9/805.2 kB 220.8 kB/s eta 0:00:03\n",
                        "   --------------- ---------------------- 337.9/805.2 kB 220.8 kB/s eta 0:00:03\n",
                        "   ---------------- --------------------- 358.4/805.2 kB 222.8 kB/s eta 0:00:03\n",
                        "   ---------------- --------------------- 358.4/805.2 kB 222.8 kB/s eta 0:00:03\n",
                        "   ----------------- -------------------- 368.6/805.2 kB 220.6 kB/s eta 0:00:02\n",
                        "   ------------------ ------------------- 389.1/805.2 kB 224.5 kB/s eta 0:00:02\n",
                        "   ------------------- ------------------ 409.6/805.2 kB 230.3 kB/s eta 0:00:02\n",
                        "   ------------------- ------------------ 419.8/805.2 kB 227.9 kB/s eta 0:00:02\n",
                        "   ------------------- ------------------ 419.8/805.2 kB 227.9 kB/s eta 0:00:02\n",
                        "   -------------------- ----------------- 440.3/805.2 kB 233.2 kB/s eta 0:00:02\n",
                        "   -------------------- ----------------- 440.3/805.2 kB 233.2 kB/s eta 0:00:02\n",
                        "   --------------------- ---------------- 450.6/805.2 kB 223.6 kB/s eta 0:00:02\n",
                        "   ---------------------- --------------- 471.0/805.2 kB 228.6 kB/s eta 0:00:02\n",
                        "   ---------------------- --------------- 471.0/805.2 kB 228.6 kB/s eta 0:00:02\n",
                        "   ---------------------- --------------- 471.0/805.2 kB 228.6 kB/s eta 0:00:02\n",
                        "   ----------------------- -------------- 491.5/805.2 kB 228.2 kB/s eta 0:00:02\n",
                        "   ----------------------- -------------- 491.5/805.2 kB 228.2 kB/s eta 0:00:02\n",
                        "   ----------------------- -------------- 501.8/805.2 kB 223.1 kB/s eta 0:00:02\n",
                        "   ------------------------ ------------- 522.2/805.2 kB 225.9 kB/s eta 0:00:02\n",
                        "   ------------------------- ------------ 532.5/805.2 kB 224.3 kB/s eta 0:00:02\n",
                        "   -------------------------- ----------- 553.0/805.2 kB 228.5 kB/s eta 0:00:02\n",
                        "   -------------------------- ----------- 553.0/805.2 kB 228.5 kB/s eta 0:00:02\n",
                        "   --------------------------- ---------- 583.7/805.2 kB 232.3 kB/s eta 0:00:01\n",
                        "   --------------------------- ---------- 583.7/805.2 kB 232.3 kB/s eta 0:00:01\n",
                        "   ---------------------------- --------- 593.9/805.2 kB 232.0 kB/s eta 0:00:01\n",
                        "   ---------------------------- --------- 614.4/805.2 kB 234.4 kB/s eta 0:00:01\n",
                        "   ----------------------------- -------- 624.6/805.2 kB 235.5 kB/s eta 0:00:01\n",
                        "   ------------------------------ ------- 645.1/805.2 kB 240.4 kB/s eta 0:00:01\n",
                        "   ------------------------------- ------ 665.6/805.2 kB 241.0 kB/s eta 0:00:01\n",
                        "   ------------------------------- ------ 675.8/805.2 kB 243.5 kB/s eta 0:00:01\n",
                        "   -------------------------------- ----- 696.3/805.2 kB 243.9 kB/s eta 0:00:01\n",
                        "   -------------------------------- ----- 696.3/805.2 kB 243.9 kB/s eta 0:00:01\n",
                        "   --------------------------------- ---- 706.6/805.2 kB 242.2 kB/s eta 0:00:01\n",
                        "   ---------------------------------- --- 727.0/805.2 kB 246.7 kB/s eta 0:00:01\n",
                        "   ----------------------------------- -- 747.5/805.2 kB 248.3 kB/s eta 0:00:01\n",
                        "   ----------------------------------- -- 747.5/805.2 kB 248.3 kB/s eta 0:00:01\n",
                        "   ------------------------------------ - 778.2/805.2 kB 250.7 kB/s eta 0:00:01\n",
                        "   ------------------------------------ - 778.2/805.2 kB 250.7 kB/s eta 0:00:01\n",
                        "   -------------------------------------  798.7/805.2 kB 252.3 kB/s eta 0:00:01\n",
                        "   -------------------------------------- 805.2/805.2 kB 251.9 kB/s eta 0:00:00\n",
                        "Installing collected packages: lightning-utilities, torchmetrics, pytorch_lightning\n",
                        "Successfully installed lightning-utilities-0.9.0 pytorch_lightning-2.1.0 torchmetrics-1.2.0\n",
                        "Note: you may need to restart the kernel to use updated packages.\n"
                    ]
                }
            ],
            "source": [
                "%pip install pytorch_lightning\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "12fb79a8",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\Users\\sabri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
                        "  warn(\n"
                    ]
                }
            ],
            "source": [
                "import random\n",
                "import math\n",
                "import numpy as np\n",
                "\n",
                "import torch\n",
                "from torch import nn\n",
                "import torch.nn.functional as F\n",
                "\n",
                "import pytorch_lightning as pl\n",
                "\n",
                "# check if notebook is in colab\n",
                "try:\n",
                "    # install ezkl\n",
                "    import google.colab\n",
                "    import subprocess\n",
                "    import sys\n",
                "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"ezkl\"])\n",
                "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"onnx\"])\n",
                "\n",
                "# rely on local installation of ezkl if the notebook is not in colab\n",
                "except:\n",
                "    pass\n",
                "\n",
                "\n",
                "# uncomment for more descriptive logging \n",
                "# import logging\n",
                "# FORMAT = '%(levelname)s %(name)s %(asctime)-15s %(filename)s:%(lineno)d %(message)s'\n",
                "# logging.basicConfig(format=FORMAT)\n",
                "# logging.getLogger().setLevel(logging.DEBUG)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "8638e94e",
            "metadata": {},
            "outputs": [],
            "source": [
                "class BaseDataModule(pl.LightningDataModule):\n",
                "  def __init__(self, batch_size=32, split=0.8, *args, **kwargs):\n",
                "    super().__init__()\n",
                "    self.ds_X, self.ds_Y = self.get_dataset(*args, **kwargs)\n",
                "    self.split = int(self.ds_X.shape[0]*split)\n",
                "    self.batch_size = batch_size\n",
                "\n",
                "  def train_dataloader(self):\n",
                "    ds_X_train, ds_Y_train = self.ds_X[0:self.split], self.ds_Y[0:self.split]\n",
                "    return torch.utils.data.DataLoader(list(zip(ds_X_train, ds_Y_train)), batch_size=self.batch_size)\n",
                "\n",
                "  def val_dataloader(self):\n",
                "    ds_X_test, ds_Y_test = self.ds_X[self.split:], self.ds_Y[self.split:]\n",
                "    return torch.utils.data.DataLoader(list(zip(ds_X_test, ds_Y_test)), batch_size=self.batch_size)\n",
                "\n",
                "class ReverseDataModule(BaseDataModule):\n",
                "  def get_dataset(self, cnt=10000, seq_len=6):\n",
                "    ds = np.random.randint(0, 10, size=(cnt, seq_len))\n",
                "    return ds, ds[:, ::-1].ravel().reshape(cnt, seq_len)\n",
                "  \n",
                "# dataset idea from https://github.com/karpathy/minGPT/blob/master/play_math.ipynb\n",
                "class AdditionDataModule(BaseDataModule):\n",
                "  def get_dataset(self):\n",
                "    ret = []\n",
                "    for i in range(100):\n",
                "      for j in range(100):\n",
                "        s = i+j\n",
                "        ret.append([i//10, i%10, j//10, j%10, s//100, (s//10)%10, s%10])\n",
                "    ds = np.array(ret)\n",
                "    return ds[:, 0:6], np.copy(ds[:, 1:])    \n",
                "\n",
                "# this is the hardest to learn and requires 4 layers\n",
                "class ParityDataModule(BaseDataModule):\n",
                "  def get_dataset(self, seq_len=10):\n",
                "    ds_X, ds_Y = [], []\n",
                "    for i in range(2**seq_len):\n",
                "      x = [int(x) for x in list(bin(i)[2:].rjust(seq_len, '0'))]\n",
                "      ds_X.append(x)\n",
                "      ds_Y.append((np.cumsum(x)%2).tolist())\n",
                "    return np.array(ds_X), np.array(ds_Y)\n",
                "  \n",
                "class WikipediaDataModule(BaseDataModule):\n",
                "  def get_dataset(self, seq_len=50):\n",
                "    global enwik8\n",
                "    if 'enwik8' not in globals():\n",
                "      import requests\n",
                "      enwik8_zipped = requests.get(\"https://data.deepai.org/enwik8.zip\").content\n",
                "      from zipfile import ZipFile\n",
                "      import io\n",
                "      enwik8 = ZipFile(io.BytesIO(enwik8_zipped)).read('enwik8')\n",
                "    en = np.frombuffer(enwik8, dtype=np.uint8).astype(np.int)\n",
                "    en = en[0:-seq_len+1]\n",
                "    en[en>127] = 127\n",
                "    return en[0:-1].reshape(-1, seq_len), en[1:].reshape(-1, seq_len)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "323554ca",
            "metadata": {},
            "outputs": [],
            "source": [
                "def attention(queries, keys, values):\n",
                "  d = queries.shape[-1]\n",
                "  scores = torch.matmul(queries, keys.transpose(-2,-1))/math.sqrt(d)\n",
                "  attention_weights = F.softmax(scores, dim=-1)\n",
                "  return torch.matmul(attention_weights, values)\n",
                "\n",
                "class MultiHeadAttention(nn.Module):\n",
                "  def __init__(self, embed_dim, num_heads):\n",
                "    super(MultiHeadAttention, self).__init__()\n",
                "    self.embed_dim, self.num_heads = embed_dim, num_heads\n",
                "    assert embed_dim % num_heads == 0\n",
                "    self.projection_dim = embed_dim // num_heads\n",
                "    \n",
                "    self.W_q = nn.Linear(embed_dim, embed_dim)\n",
                "    self.W_k = nn.Linear(embed_dim, embed_dim)\n",
                "    self.W_v = nn.Linear(embed_dim, embed_dim)\n",
                "    self.W_o = nn.Linear(embed_dim, embed_dim)\n",
                "\n",
                "  def transpose(self, x):\n",
                "    x = x.reshape(x.shape[0], x.shape[1], self.num_heads, self.projection_dim)\n",
                "    return x.permute(0, 2, 1, 3)\n",
                "  \n",
                "  def transpose_output(self, x):\n",
                "    x = x.permute(0, 2, 1, 3)\n",
                "    return x.reshape(x.shape[0], x.shape[1], self.embed_dim)\n",
                "    \n",
                "  def forward(self, q, k, v):\n",
                "    q = self.transpose(self.W_q(q))\n",
                "    k = self.transpose(self.W_k(k))\n",
                "    v = self.transpose(self.W_v(v))\n",
                "    output = attention(q, k, v)\n",
                "    return self.W_o(self.transpose_output(output))\n",
                "  \n",
                "class TransformerBlock(nn.Module):\n",
                "  def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
                "    super(TransformerBlock, self).__init__()\n",
                "    self.att = MultiHeadAttention(embed_dim, num_heads)\n",
                "    self.ffn = nn.Sequential(\n",
                "      nn.Linear(embed_dim, ff_dim), nn.ReLU(), nn.Linear(ff_dim, embed_dim)\n",
                "    )\n",
                "    self.layernorm1 = nn.LayerNorm(embed_dim)\n",
                "    self.layernorm2 = nn.LayerNorm(embed_dim)\n",
                "    self.dropout = nn.Dropout(rate)\n",
                "    \n",
                "  def forward(self, x):\n",
                "    x = self.layernorm1(x + self.dropout(self.att(x, x, x)))\n",
                "    x = self.layernorm2(x + self.dropout(self.ffn(x)))\n",
                "    return x\n",
                "  \n",
                "class TokenAndPositionEmbedding(nn.Module):\n",
                "  def __init__(self, maxlen, vocab_size, embed_dim):\n",
                "    super(TokenAndPositionEmbedding, self).__init__()\n",
                "    self.token_emb = nn.Embedding(vocab_size, embed_dim)\n",
                "    self.pos_emb = nn.Embedding(maxlen, embed_dim)\n",
                "  def forward(self, x):\n",
                "    pos = torch.arange(0, x.size(1), dtype=torch.int32, device=x.device)\n",
                "    return self.token_emb(x) + self.pos_emb(pos).view(1, x.size(1), -1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "167e42e3",
            "metadata": {},
            "outputs": [],
            "source": [
                "class LittleTransformer(pl.LightningModule):\n",
                "  def __init__(self, seq_len=6, max_value=10, layer_count=2, embed_dim=128, num_heads=4, ff_dim=32):\n",
                "    super().__init__()\n",
                "    self.max_value = max_value\n",
                "    self.model = nn.Sequential(\n",
                "      TokenAndPositionEmbedding(seq_len, max_value, embed_dim),\n",
                "      *[TransformerBlock(embed_dim, num_heads, ff_dim) for x in range(layer_count)],\n",
                "      nn.Linear(embed_dim, max_value),\n",
                "      nn.LogSoftmax(dim=-1))\n",
                "    \n",
                "  def forward(self, x):\n",
                "    return self.model(x)\n",
                "  \n",
                "  def training_step(self, batch, batch_idx):\n",
                "    x, y = batch\n",
                "    output = self.model(x)\n",
                "    loss = F.nll_loss(output.view(-1, self.max_value), y.view(-1))\n",
                "    self.log(\"train_loss\", loss)\n",
                "    return loss\n",
                "  \n",
                "  def validation_step(self, val_batch, batch_idx):\n",
                "    x, y = val_batch\n",
                "    pred = self.model(x).argmax(dim=2)\n",
                "    val_accuracy = (pred == y).type(torch.float).mean()\n",
                "    self.log(\"val_accuracy\", val_accuracy, prog_bar=True)\n",
                "  \n",
                "  def configure_optimizers(self):\n",
                "    if self.device.type == 'cuda':\n",
                "      import apex\n",
                "      return apex.optimizers.FusedAdam(self.parameters(), lr=3e-4)\n",
                "    else:\n",
                "      return torch.optim.Adam(self.parameters(), lr=3e-4)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "a2f48c98",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "GPU available: False, used: False\n",
                        "TPU available: False, using: 0 TPU cores\n",
                        "IPU available: False, using: 0 IPUs\n",
                        "HPU available: False, using: 0 HPUs\n",
                        "Missing logger folder: c:\\Users\\sabri\\OneDrive\\Documents\\Projects\\Proof-of-Assets-Protocol\\zkml\\transformer-demo\\lightning_logs\n",
                        "\n",
                        "  | Name  | Type       | Params\n",
                        "-------------------------------------\n",
                        "0 | model | Sequential | 153 K \n",
                        "-------------------------------------\n",
                        "153 K     Trainable params\n",
                        "0         Non-trainable params\n",
                        "153 K     Total params\n",
                        "0.613     Total estimated model params size (MB)\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "347fffefbacb42caa20eca8709946983",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\Users\\sabri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
                        "c:\\Users\\sabri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
                        "`Trainer.fit` stopped: `max_epochs=0` reached.\n"
                    ]
                }
            ],
            "source": [
                "model = LittleTransformer(seq_len=6)\n",
                "trainer = pl.Trainer(enable_progress_bar=True, max_epochs=0)\n",
                "data = AdditionDataModule(batch_size=64)\n",
                "#data = ReverseDataModule(cnt=1000, seq_len=20)\n",
                "#data = ParityDataModule(seq_len=14)\n",
                "trainer.fit(model, data)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "fa7d277e",
            "metadata": {},
            "source": [
                "## EZKL "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "6f339a28",
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "import os \n",
                "\n",
                "model_path = os.path.join('network.onnx')\n",
                "compiled_model_path = os.path.join('network.compiled')\n",
                "pk_path = os.path.join('test.pk')\n",
                "vk_path = os.path.join('test.vk')\n",
                "settings_path = os.path.join('settings.json')\n",
                "srs_path = os.path.join('kzg.srs')\n",
                "witness_path = os.path.join('witness.json')\n",
                "data_path = os.path.join('input.json')\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "27ce542b",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "tensor([[1, 1, 1, 1, 1, 1]])\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "C:\\Users\\sabri\\AppData\\Local\\Temp\\ipykernel_21852\\1190420391.py:3: TracerWarning: Converting a tensor to a Python float might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
                        "  scores = torch.matmul(queries, keys.transpose(-2,-1))/math.sqrt(d)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'input_data': [[1, 1, 1, 1, 1, 1]]}\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\Users\\sabri\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\onnx\\utils.py:1686: UserWarning: The exported ONNX model failed ONNX shape inference. The model will not be executable by the ONNX Runtime. If this is unintended and you believe there is a bug, please report an issue at https://github.com/pytorch/pytorch/issues. Error reported by strict ONNX shape inference: [ShapeInferenceError] (op_type:ConstantOfShape, node name: /model/model.0/ConstantOfShape): input typestr: T1, has unsupported type: tensor(int32) (Triggered internally at ..\\torch\\csrc\\jit\\serialization\\export.cpp:1421.)\n",
                        "  _C._check_onnx_proto(proto)\n"
                    ]
                }
            ],
            "source": [
                "\n",
                "import json \n",
                "# After training, export to onnx (network.onnx) and create a data file (input.json)\n",
                "x = torch.ones([1, 6], dtype=torch.long)\n",
                "x = x.reshape([1, 6])\n",
                "\n",
                "print(x)\n",
                "\n",
                "# Flips the neural net into inference mode\n",
                "model.eval()\n",
                "model.to('cpu')\n",
                "\n",
                "    # Export the model\n",
                "torch.onnx.export(model,               # model being run\n",
                "                      x,                   # model input (or a tuple for multiple inputs)\n",
                "                      model_path,            # where to save the model (can be a file or file-like object)\n",
                "                      export_params=True,        # store the trained parameter weights inside the model file\n",
                "                      opset_version=10,          # the ONNX version to export the model to\n",
                "                      do_constant_folding=True,  # whether to execute constant folding for optimization\n",
                "                      input_names = ['input'],   # the model's input names\n",
                "                      output_names = ['output'], # the model's output names\n",
                "                      dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
                "                                    'output' : {0 : 'batch_size'}})\n",
                "\n",
                "data_array = ((x).detach().numpy()).reshape([-1]).tolist()\n",
                "\n",
                "data_json = dict(input_data = [data_array])\n",
                "\n",
                "print(data_json)\n",
                "\n",
                "    # Serialize data into file:\n",
                "json.dump( data_json, open(data_path, 'w' ))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "36ddc6f9",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "'RUST_LOG' is not recognized as an internal or external command,\n",
                        "operable program or batch file.\n"
                    ]
                }
            ],
            "source": [
                "import ezkl \n",
                "\n",
                "!RUST_LOG=trace\n",
                "# TODO: Dictionary outputs\n",
                "res = ezkl.gen_settings(model_path, settings_path)\n",
                "assert res == True"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "2fe6d972",
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "\n",
                "res = await ezkl.calibrate_settings(data_path, model_path, settings_path, \"resources\")\n",
                "assert res == True\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "0990f5a8",
            "metadata": {},
            "outputs": [],
            "source": [
                "res = ezkl.compile_circuit(model_path, compiled_model_path, settings_path)\n",
                "assert res == True"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "1b80dc01",
            "metadata": {},
            "outputs": [],
            "source": [
                "# srs path\n",
                "res = ezkl.get_srs(srs_path, settings_path)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "54cbde29",
            "metadata": {},
            "outputs": [],
            "source": [
                "# now generate the witness file \n",
                "witness_path = \"gan_witness.json\"\n",
                "\n",
                "res = ezkl.gen_witness(data_path, compiled_model_path, witness_path)\n",
                "assert os.path.isfile(witness_path)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "28760638",
            "metadata": {},
            "outputs": [],
            "source": [
                "res = ezkl.mock(witness_path, compiled_model_path)\n",
                "assert res == True"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "id": "5e595112",
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "# HERE WE SETUP THE CIRCUIT PARAMS\n",
                "# WE GOT KEYS\n",
                "# WE GOT CIRCUIT PARAMETERS\n",
                "# EVERYTHING ANYONE HAS EVER NEEDED FOR ZK\n",
                "\n",
                "res = ezkl.setup(\n",
                "        compiled_model_path,\n",
                "        vk_path,\n",
                "        pk_path,\n",
                "        srs_path,\n",
                "    )\n",
                "\n",
                "assert res == True\n",
                "assert os.path.isfile(vk_path)\n",
                "assert os.path.isfile(pk_path)\n",
                "assert os.path.isfile(settings_path)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "id": "d37adaef",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'instances': [[[4050710420132988378, 4592888871911207431, 9635431550596092189, 3094830811046949920], [15005293851080393895, 683888734767854546, 9039942799075711334, 2497519177688949272], [4050710420132988378, 4592888871911207431, 9635431550596092189, 3094830811046949920], [15640967717350016944, 1083587571622173881, 16796151735874178085, 223793648293068984], [15640967717350016944, 1083587571622173881, 16796151735874178085, 223793648293068984], [7607641727867815613, 16556411302731023062, 17646720475294886839, 1433442205810571550], [2027943787124229356, 16103540445844736762, 3104983751552068225, 3292726628869754199], [640851020385093383, 9567146782923033812, 4330744889306511013, 1216896917296678190], [4576080355412412247, 1512624489246571065, 15361688789837648834, 3475597155891057207], [7607641727867815613, 16556411302731023062, 17646720475294886839, 1433442205810571550], [15640967717350016944, 1083587571622173881, 16796151735874178085, 223793648293068984], [2605877110841017648, 10179533699905221008, 2335576826463281984, 600935813247588460], [1145248390108415555, 13620993939777248668, 2208036832513118034, 294767351167837501], [2605877110841017648, 10179533699905221008, 2335576826463281984, 600935813247588460], [2605877110841017648, 10179533699905221008, 2335576826463281984, 600935813247588460], [4050710420132988378, 4592888871911207431, 9635431550596092189, 3094830811046949920], [640851020385093383, 9567146782923033812, 4330744889306511013, 1216896917296678190], [17626966373362042906, 13008607022795061471, 4203204895356347063, 910728455216927231], [5642615637411891348, 15944024385748835866, 1195144464428564252, 2049403309859661281], [5511339140865590471, 1151428632039179771, 9762971544546256139, 3400999273126700879], [4576080355412412247, 1512624489246571065, 15361688789837648834, 3475597155891057207], [15640967717350016944, 1083587571622173881, 16796151735874178085, 223793648293068984], [9068270448600417706, 13114951062858995402, 17774260469245050789, 1739610667890322509], [640851020385093383, 9567146782923033812, 4330744889306511013, 1216896917296678190], [1145248390108415555, 13620993939777248668, 2208036832513118034, 294767351167837501], [1145248390108415555, 13620993939777248668, 2208036832513118034, 294767351167837501], [9068270448600417706, 13114951062858995402, 17774260469245050789, 1739610667890322509], [6089272464582378763, 13674165959809215633, 8993564619457469897, 709208457504535140], [17626966373362042906, 13008607022795061471, 4203204895356347063, 910728455216927231], [6089272464582378763, 13674165959809215633, 8993564619457469897, 709208457504535140], [4576080355412412247, 1512624489246571065, 15361688789837648834, 3475597155891057207], [4576080355412412247, 1512624489246571065, 15361688789837648834, 3475597155891057207], [2605877110841017648, 10179533699905221008, 2335576826463281984, 600935813247588460], [9651380926432676332, 16358392262988194125, 13579389496664308810, 2538442298960715248], [12026295867062354952, 1243103631718074777, 259246949288130442, 1467116967303161903], [15640967717350016944, 1083587571622173881, 16796151735874178085, 223793648293068984], [640851020385093383, 9567146782923033812, 4330744889306511013, 1216896917296678190], [13040267760624469630, 71501817785667350, 11035110861918940363, 3113480281738039002], [5043709748139001359, 10555398597497651226, 12562330167191952486, 3438298214508879043], [2605877110841017648, 10179533699905221008, 2335576826463281984, 600935813247588460], [13040267760624469630, 71501817785667350, 11035110861918940363, 3113480281738039002], [2605877110841017648, 10179533699905221008, 2335576826463281984, 600935813247588460], [5511339140865590471, 1151428632039179771, 9762971544546256139, 3400999273126700879], [4576080355412412247, 1512624489246571065, 15361688789837648834, 3475597155891057207], [7607641727867815613, 16556411302731023062, 17646720475294886839, 1433442205810571550], [5043709748139001359, 10555398597497651226, 12562330167191952486, 3438298214508879043], [2605877110841017648, 10179533699905221008, 2335576826463281984, 600935813247588460], [4576080355412412247, 1512624489246571065, 15361688789837648834, 3475597155891057207], [15640967717350016944, 1083587571622173881, 16796151735874178085, 223793648293068984], [1145248390108415555, 13620993939777248668, 2208036832513118034, 294767351167837501], [1145248390108415555, 13620993939777248668, 2208036832513118034, 294767351167837501], [13975526546077647854, 18157050034287827672, 5436393616627547667, 3038882398973682674], [6089272464582378763, 13674165959809215633, 8993564619457469897, 709208457504535140], [16166337652629440813, 16450067262667089131, 4075664901406183113, 604559993137176272], [1145248390108415555, 13620993939777248668, 2208036832513118034, 294767351167837501], [16166337652629440813, 16450067262667089131, 4075664901406183113, 604559993137176272], [9651380926432676332, 16358392262988194125, 13579389496664308810, 2538442298960715248], [2605877110841017648, 10179533699905221008, 2335576826463281984, 600935813247588460], [7008735838594925624, 11167785514479838422, 10567162104348723457, 2822337110459789313], [4576080355412412247, 1512624489246571065, 15361688789837648834, 3475597155891057207]]], 'proof': '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', 'transcript_type': 'EVM'}\n"
                    ]
                }
            ],
            "source": [
                "# GENERATE A PROOF\n",
                "\n",
                "\n",
                "proof_path = os.path.join('test.pf')\n",
                "\n",
                "res = ezkl.prove(\n",
                "        witness_path,\n",
                "        compiled_model_path,\n",
                "        pk_path,\n",
                "        proof_path,\n",
                "        srs_path,\n",
                "        \"single\",\n",
                "    )\n",
                "\n",
                "print(res)\n",
                "assert os.path.isfile(proof_path)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "id": "5b58acd5",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "verified\n"
                    ]
                }
            ],
            "source": [
                "# VERIFY IT\n",
                "res = ezkl.verify(\n",
                "        proof_path,\n",
                "        settings_path,\n",
                "        vk_path,\n",
                "        srs_path,\n",
                "    )\n",
                "\n",
                "assert res == True\n",
                "print(\"verified\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "id": "7b2232c7",
            "metadata": {},
            "outputs": [],
            "source": [
                "sol_code_path = os.path.join('Verifier.sol')\n",
                "abi_path = os.path.join('Verifier.abi')\n",
                "\n",
                "res = ezkl.create_evm_verifier(\n",
                "        vk_path,\n",
                "        srs_path,\n",
                "        settings_path,\n",
                "        sol_code_path,\n",
                "        abi_path\n",
                "    )\n",
                "\n",
                "assert res == True\n",
                "assert os.path.isfile(sol_code_path)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "64bd70f3",
            "metadata": {},
            "outputs": [],
            "source": [
                "onchain_input_array = []\n",
                "\n",
                "# using a loop\n",
                "# avoiding printing last comma\n",
                "formatted_output = \"[\"\n",
                "for i, value in enumerate(res[\"instances\"]):\n",
                "    for j, field_element in enumerate(value):\n",
                "        onchain_input_array.append(ezkl.vecu64_to_felt(field_element))\n",
                "        formatted_output += str(onchain_input_array[-1])\n",
                "        if j != len(value) - 1:\n",
                "            formatted_output += \", \"\n",
                "    formatted_output += \"]\"\n",
                "\n",
                "# This will be the values you use onchain\n",
                "# copy them over to remix and see if they verify\n",
                "# What happens when you change a value?\n",
                "print(\"pubInputs: \", formatted_output)\n",
                "print(\"proof: \", \"0x\" + res[\"proof\"])"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
